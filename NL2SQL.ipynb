{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f851893e-f3cc-4ce6-9b74-c5ac10a436ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "76c3aefd-00b6-47c5-996a-99f44006b85d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import boto3\n",
    "import re\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "# import sentencepiece\n",
    "import pandas as pd\n",
    "from anthropic import Anthropic\n",
    "CLAUDE = Anthropic()\n",
    "import multiprocessing\n",
    "import subprocess\n",
    "import shutil\n",
    "import os\n",
    "import codecs\n",
    "import uuid\n",
    "REDSHIFT=boto3.client('redshift-data')\n",
    "S3=boto3.client('s3')\n",
    "from botocore.config import Config\n",
    "config = Config(\n",
    "    read_timeout=600,\n",
    "    retries = dict(\n",
    "        max_attempts = 5\n",
    "    )\n",
    ")\n",
    "from botocore.exceptions import ClientError\n",
    "bedrock_runtime=boto3.client(service_name='bedrock-runtime',region_name='us-east-1',config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61e948f-67b0-4c72-ad33-930071495bed",
   "metadata": {},
   "source": [
    "## REDSHIFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91de54b-7567-4aee-8ffd-7f5c83ba2397",
   "metadata": {},
   "source": [
    "Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "eb445560-2bac-48c8-97ba-f5dc933b8893",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bedrock_streemer(response):\n",
    "    stream = response.get('body')\n",
    "    answer = \"\"\n",
    "    i = 1\n",
    "    if stream:\n",
    "        for event in stream:\n",
    "            chunk = event.get('chunk')\n",
    "            if  chunk:\n",
    "                chunk_obj = json.loads(chunk.get('bytes').decode())\n",
    "                if \"delta\" in chunk_obj:                    \n",
    "                    delta = chunk_obj['delta']\n",
    "                    if \"text\" in delta:\n",
    "                        text=delta['text'] \n",
    "                        print(text, end=\"\")\n",
    "                        answer+=str(text)       \n",
    "                        i+=1\n",
    "                if \"amazon-bedrock-invocationMetrics\" in chunk_obj:\n",
    "                    input_tokens= chunk_obj['amazon-bedrock-invocationMetrics']['inputTokenCount']\n",
    "                    output_tokens=chunk_obj['amazon-bedrock-invocationMetrics']['outputTokenCount']\n",
    "                    print(f\"\\nInput Tokens: {input_tokens}\\nOutput Tokens: {output_tokens}\")\n",
    "    return answer,input_tokens, output_tokens\n",
    "\n",
    "def bedrock_claude_(chat_history,params, prompt):\n",
    "    content=[{\n",
    "        \"type\": \"text\",\n",
    "        \"text\": prompt\n",
    "            }]\n",
    "    chat_history.append({\"role\": \"user\",\n",
    "            \"content\": content})\n",
    "    prompt = {\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": params[\"token\"],\n",
    "        \"temperature\": params[\"temp\"],\n",
    "        \"system\":params[\"system_message\"],\n",
    "        \"messages\": chat_history\n",
    "    }\n",
    "    answer = \"\"\n",
    "    prompt = json.dumps(prompt)\n",
    "    # print(chat_history)\n",
    "    response = bedrock_runtime.invoke_model_with_response_stream(body=prompt, modelId=params[\"sql_model\"], accept=\"application/json\", contentType=\"application/json\")\n",
    "    answer,input_tokens,output_tokens=bedrock_streemer(response) \n",
    "    return answer, input_tokens, output_tokens\n",
    "\n",
    "def _invoke_bedrock_with_retries(chat_history, params, question):\n",
    "    max_retries = 5\n",
    "    backoff_base = 2\n",
    "    max_backoff = 3  # Maximum backoff time in seconds\n",
    "    retries = 0\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            response,input_tokens,output_tokens= bedrock_claude_(chat_history, params, question)\n",
    "            return response,input_tokens,output_tokens\n",
    "        except ClientError as e:\n",
    "            if e.response['Error']['Code'] == 'ThrottlingException':\n",
    "                if retries < max_retries:\n",
    "                    # Throttling, exponential backoff\n",
    "                    sleep_time = min(max_backoff, backoff_base ** retries + random.uniform(0, 1))\n",
    "                    time.sleep(sleep_time)\n",
    "                    retries += 1\n",
    "                else:\n",
    "                    raise e\n",
    "            elif e.response['Error']['Code'] == 'ModelStreamErrorException':\n",
    "                if retries < max_retries:\n",
    "                    # Throttling, exponential backoff\n",
    "                    sleep_time = min(max_backoff, backoff_base ** retries + random.uniform(0, 1))\n",
    "                    time.sleep(sleep_time)\n",
    "                    retries += 1\n",
    "                else:\n",
    "                    raise e\n",
    "            else:\n",
    "                # Some other API error, rethrow\n",
    "                raise\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "de196317-7d86-425c-9efa-8f496fbe45fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query_llm(prompts,params):   \n",
    "    \"\"\"\n",
    "    Function to prompt the model to generate sql statements from natural language\n",
    "    \"\"\"\n",
    "    import boto3\n",
    "    import json   \n",
    "    answer, input_token, output_token=_invoke_bedrock_with_retries([], params, prompts)        \n",
    "    return answer\n",
    "\n",
    "\n",
    "\n",
    "def qna_llm(prompts,params):\n",
    "    \"\"\"\n",
    "    Function to prompt the model to generate natural language answers from sql results\n",
    "    \"\"\"\n",
    "    import json \n",
    "    answer, input_token, output_token=_invoke_bedrock_with_retries([], params, prompts)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "dec641b4-70a4-45d3-86cb-bd876d15e354",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def chunk_csv_rows(csv_rows, max_token_per_chunk):\n",
    "    \"\"\"\n",
    "    Chunk CSV rows based on the maximum token count per chunk.\n",
    "    Args:\n",
    "        csv_rows (list): List of CSV rows.\n",
    "        max_token_per_chunk (int, optional): Maximum token count per chunk.\n",
    "    Returns:\n",
    "        list: List of chunks containing CSV rows.\n",
    "    Raises:\n",
    "        ValueError: If a single CSV row exceeds the specified max_token_per_chunk.\n",
    "    \"\"\"\n",
    "    header = csv_rows[0]  # Assuming the first row is the header\n",
    "    csv_rows = csv_rows[1:]  # Remove the header from the list\n",
    "    current_chunk = []\n",
    "    current_token_count = 0\n",
    "    chunks = []\n",
    "    header_token=len(mixtral_counter(\"mistralai/Mixtral-8x7B-v0.1\").encode(header))\n",
    "    for row in csv_rows:\n",
    "        token = len(mixtral_counter(\"mistralai/Mixtral-8x7B-v0.1\").encode(row))\n",
    "        if current_token_count + token+header_token <= max_token_per_chunk:\n",
    "            current_chunk.append(row)\n",
    "            current_token_count += token\n",
    "        else:\n",
    "            if not current_chunk:\n",
    "                raise ValueError(\"A single CSV row exceeds the specified max_token_per_chunk.\")\n",
    "            header_and_chunk=[header]+current_chunk\n",
    "            chunks.append(\"\\n\".join([x for x in header_and_chunk]))\n",
    "            current_chunk = [row]\n",
    "            current_token_count = token\n",
    "\n",
    "    if current_chunk:\n",
    "        last_chunk_and_header=[header]+current_chunk\n",
    "        chunks.append(\"\\n\".join([x for x in last_chunk_and_header]))\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "248fc3be-eede-4b2c-a926-8d5c7a04f30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tables_redshift(identifier, database,  schema,serverless,db_user=None,):\n",
    "    \"\"\"\n",
    "    Get a list of table names in a specified schema from an Amazon Redshift cluster.\n",
    "    Args:\n",
    "        identifier (str): The identifier of the Redshift cluster.\n",
    "        database (str): The name of the database containing the tables.\n",
    "        db_user (str): The username used to authenticate with the Redshift cluster.\n",
    "        schema (str): The schema pattern to filter tables.\n",
    "    Returns:\n",
    "        list: A list of table names in the specified schema.\n",
    "    \"\"\"\n",
    "    if serverless:\n",
    "        tables_ls = REDSHIFT.list_tables(\n",
    "       WorkgroupName=identifier,\n",
    "        Database=database,\n",
    "        SchemaPattern=schema\n",
    "        )\n",
    "    else:\n",
    "        tables_ls = REDSHIFT.list_tables(\n",
    "        ClusterIdentifier=identifier,\n",
    "        Database=database,\n",
    "        DbUser=db_user,\n",
    "        SchemaPattern=schema\n",
    "        )\n",
    "    return [x['name'] for x in  tables_ls['Tables']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "47e81566-6e5e-4771-9fdd-65343c388f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db_redshift(identifier, database,serverless, db_user=None, ):\n",
    "    \"\"\"\n",
    "    Get a list of databases from an Amazon Redshift cluster.\n",
    "    Args:\n",
    "        identifier (str): The identifier of the Redshift cluster.\n",
    "        database (str): The name of the database containing the tables.\n",
    "        db_user (str): The username used to authenticate with the Redshift cluster.\n",
    "    Returns:\n",
    "        list: A list of databases in the Redshift cluster.\n",
    "    \"\"\"\n",
    "    if serverless:\n",
    "        db_ls = REDSHIFT.list_databases(\n",
    "        WorkgroupName=identifier,\n",
    "        Database=database,\n",
    "        )    \n",
    "    else:\n",
    "        db_ls = REDSHIFT.list_databases(\n",
    "        ClusterIdentifier=identifier,\n",
    "        Database=database,\n",
    "        DbUser=db_user\n",
    "        )\n",
    "    return db_ls['Databases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "34cf5577-7130-4302-a03f-4f5a60db0a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_schema_redshift(identifier, database, serverless, db_user=None,):\n",
    "    \"\"\"\n",
    "    Get a list of schemas from an Amazon Redshift cluster.\n",
    "    Args:\n",
    "        identifier (str): The identifier of the Redshift cluster.\n",
    "        database (str): The name of the database containing the schemas.\n",
    "        db_user (str): The username used to authenticate with the Redshift cluster.\n",
    "    Returns:\n",
    "        list: A list of schemas in the Redshift cluster.\n",
    "    \"\"\"\n",
    "    if serverless:\n",
    "        schema_ls = REDSHIFT.list_schemas(\n",
    "        WorkgroupName=identifier,\n",
    "        Database=database,\n",
    "\n",
    "        )\n",
    "    else:        \n",
    "        schema_ls = REDSHIFT.list_schemas(\n",
    "        ClusterIdentifier=identifier,\n",
    "        Database=database,\n",
    "        DbUser=db_user\n",
    "        )\n",
    "    return schema_ls['Schemas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "70f38a84-47bb-481e-a348-4b32ca267b31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def execute_query_with_pagination( sql_query, identifier, database,  serverless, db_user=None,):\n",
    "    \"\"\"\n",
    "    Execute multiple SQL queries in Amazon Redshift with pagination support.\n",
    "    Args:\n",
    "        sql_query1 (str): The first SQL query to execute.\n",
    "        sql_query2 (str): The second SQL query to execute.\n",
    "        identifier (str): The identifier of the Redshift cluster.\n",
    "        database (str): The name of the database.\n",
    "        db_user (str): The username used to authenticate with the Redshift cluster.\n",
    "    Returns:\n",
    "        list: A list of results from executing the SQL queries.\n",
    "    \"\"\"\n",
    "    results_list=[]\n",
    "    if serverless:\n",
    "        response_b = REDSHIFT.batch_execute_statement(\n",
    "            WorkgroupName=identifier,\n",
    "            Database=database,\n",
    "        \n",
    "            Sqls=sql_query\n",
    "        ) \n",
    "    else:\n",
    "        response_b = REDSHIFT.batch_execute_statement(\n",
    "            ClusterIdentifier=identifier,\n",
    "            Database=database,\n",
    "            DbUser=db_user,\n",
    "            Sqls=sql_query\n",
    "        )   \n",
    "    describe_b=REDSHIFT.describe_statement(\n",
    "         Id=response_b['Id'],\n",
    "    )       \n",
    "    status=describe_b['Status']\n",
    "    print(status)\n",
    "    while status != \"FINISHED\":\n",
    "        time.sleep(1)\n",
    "        describe_b=REDSHIFT.describe_statement(\n",
    "                         Id=response_b['Id'],\n",
    "                    ) \n",
    "        status=describe_b['Status']\n",
    "        if status==\"FAILED\":\n",
    "            raise(\"Execution Failed\")\n",
    "        \n",
    "        print(status)\n",
    "    max_attempts = 5 \n",
    "    attempts = 0\n",
    "    while attempts < max_attempts:\n",
    "        try:\n",
    "            for ids in describe_b['SubStatements']:\n",
    "                result_b = REDSHIFT.get_statement_result(Id=ids['Id'])                \n",
    "                results_list.append(get_redshift_table_result(result_b))\n",
    "            break\n",
    "        except REDSHIFT.exceptions.ResourceNotFoundException as e:\n",
    "            attempts += 1\n",
    "            time.sleep(2)\n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "bb1c043c-60d0-4d34-8fdd-886d6120c40f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_redshift_table_result(response):\n",
    "    \"\"\"\n",
    "    Extracts result data from a Redshift query response and returns it as a CSV string.\n",
    "    Args:\n",
    "        response (dict): The response object from a Redshift query.\n",
    "    Returns:\n",
    "        str: A CSV string containing the result data.\n",
    "    \"\"\"\n",
    "    columns = [c['name'] for c in response['ColumnMetadata']] \n",
    "    data = []\n",
    "    for r in response['Records']:\n",
    "        row = []\n",
    "        for col in r:\n",
    "            row.append(list(col.values())[0])  \n",
    "        data.append(row)\n",
    "    df = pd.DataFrame(data, columns=columns)    \n",
    "    return df.to_csv(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "8c24a0b9-ed77-4222-bc87-af828502e2ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def execute_query_redshyft(sql_query, identifier, database, serverless,db_user=None):\n",
    "    \"\"\"\n",
    "    Execute a SQL query on an Amazon Redshift cluster.\n",
    "    Args:\n",
    "        sql_query (str): The SQL query to execute.\n",
    "        identifier (str): The identifier of the Redshift cluster.\n",
    "        database (str): The name of the database.\n",
    "        db_user (str): The username used to authenticate with the Redshift cluster.\n",
    "    Returns:\n",
    "        dict: The response object from executing the SQL query.\n",
    "    \"\"\"\n",
    "    if serverless:\n",
    "        response = REDSHIFT.execute_statement(\n",
    "        WorkgroupName=identifier,\n",
    "            Database=database,\n",
    "\n",
    "            Sql=sql_query\n",
    "        )\n",
    "    else:        \n",
    "        response = REDSHIFT.execute_statement(\n",
    "            ClusterIdentifier=identifier,\n",
    "            Database=database,\n",
    "            DbUser=db_user,\n",
    "            Sql=sql_query\n",
    "        )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "1a7c4ef0-9166-4faf-a820-0c03d8974e87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def single_execute_query(params,sql_query, identifier, database, question,serverless,db_user=None):\n",
    "    \"\"\"\n",
    "    Execute a single SQL query on an Amazon Redshift cluster and process the result.\n",
    "\n",
    "    Args:\n",
    "        sql_query (str): The SQL query to execute.\n",
    "        identifier (str): The identifier of the Redshift cluster.\n",
    "        database (str): The name of the database.\n",
    "        db_user (str): The username used to authenticate with the Redshift cluster.\n",
    "        question (str): A descriptive label or question associated with the query.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame containing the processed result of the SQL query.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    response = execute_query_redshyft(sql_query, identifier, database,serverless, db_user)\n",
    "    df=redshyft_querys(sql_query,response,question,params,identifier, \n",
    "                       database,                     \n",
    "                       question,\n",
    "                         db_user,)    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "30c4b2f5-65e8-4c9c-b0bc-f19406d7838c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def llm_debugga(question, statement, error, params): \n",
    "    \"\"\"\n",
    "    Generate debugging guidance and expected SQL correction for a PostgreSQL error.\n",
    "    Args:\n",
    "        question (str): The user's question or intent.\n",
    "        statement (str): The SQL statement that caused the error.\n",
    "        error (str): The error message encountered.\n",
    "        params (dict): Additional parameters including schema, sample data, and length.\n",
    "    Returns:\n",
    "        str: Formatted debugging guidance and expected SQL correction.\n",
    "    \"\"\"\n",
    " \n",
    "    model=\"claude\"\n",
    "    with open(f\"prompt/{params['prompt-type']}/{model}-debugger.txt\",\"r\") as f:\n",
    "        prompts=f.read()\n",
    "    values = {\n",
    "    \"error\":error,\n",
    "    \"sql\":statement,\n",
    "    \"schema\": params['schema'],\n",
    "    \"sample\": params['sample'],\n",
    "    \"question\":params['prompt']\n",
    "    }\n",
    "    prompts=prompts.format(**values)\n",
    "    answer=query_llm(prompts,params)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "aae1ae4a-1171-48c4-9799-c0d57566015b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def redshyft_querys(q_s,response,prompt,params,identifier, database, question,db_user=None,): \n",
    "    \"\"\"\n",
    "    Execute a Redshift query, handle errors, debug SQL, and return the result.\n",
    "\n",
    "    Args:\n",
    "        q_s (str): The SQL statement to execute or debug.\n",
    "        response (dict): The response object from executing the SQL statement.\n",
    "        prompt (str): The user's question or intent.\n",
    "        params (dict): Additional parameters including schema, sample data, and length.\n",
    "        identifier (str): The identifier of the Redshift cluster.\n",
    "        database (str): The name of the database.\n",
    "        db_user (str): The username used to authenticate with the Redshift cluster.\n",
    "        question (str): A descriptive label or question associated with the query.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame or str: DataFrame containing the query result, or debugging failure message with no result.\n",
    "\n",
    "    \"\"\"\n",
    "    max_execution=5\n",
    "    debug_count=max_execution\n",
    "    alert=False\n",
    "    try:\n",
    "        statement_result = REDSHIFT.get_statement_result(\n",
    "            Id=response['Id'],\n",
    "        )\n",
    "    except REDSHIFT.exceptions.ResourceNotFoundException as err:  \n",
    "        # print(err)\n",
    "        describe_statement=REDSHIFT.describe_statement(\n",
    "             Id=response['Id'],\n",
    "        )\n",
    "        query_state=describe_statement['Status']  \n",
    "        while query_state in ['SUBMITTED','PICKED','STARTED']:\n",
    "            # print(query_state)\n",
    "            time.sleep(1)\n",
    "            describe_statement=REDSHIFT.describe_statement(\n",
    "                 Id=response['Id'],\n",
    "            )\n",
    "            query_state=describe_statement['Status']\n",
    "        while (max_execution > 0 and query_state == \"FAILED\"):\n",
    "            max_execution = max_execution - 1\n",
    "            print(f\"\\nDEBUG TRIAL {max_execution}\")\n",
    "            bad_sql=describe_statement['QueryString']\n",
    "            print(f\"\\nBAD SQL:\\n{bad_sql}\")                \n",
    "            error=describe_statement['Error']\n",
    "            print(f\"\\nERROR:{error}\")\n",
    "            print(\"\\nDEBUGGIN...\")\n",
    "            cql=llm_debugga(prompt, bad_sql, error, params)            \n",
    "            idx1 = cql.index('<sql>')\n",
    "            idx2 = cql.index('</sql>')\n",
    "            q_s=cql[idx1 + len('<sql>') + 1: idx2]\n",
    "            print(f\"\\nDEBUGGED SQL\\n {q_s}\")\n",
    "            ### Guardrails to prevent the LLM from altering tables\n",
    "            if any(keyword in q_s for keyword in [\"CREATE\", \"DROP\", \"ALTER\",\"INSERT\",\"UPDATE\",\"TRUNCATE\",\"DELETE\",\"MERGE\",\"REPLACE\",\"UPSERT\"]):\n",
    "                alert=\"I AM NOT PERMITTED TO MODIFY THIS TABLE, CONTACT ADMIN.\"\n",
    "                print(alert)\n",
    "                alert=True\n",
    "                break\n",
    "            else:\n",
    "                response = execute_query_redshyft(q_s, identifier, database,params['serverless'],db_user)\n",
    "                describe_statement=REDSHIFT.describe_statement(\n",
    "                                     Id=response['Id'],\n",
    "                                )\n",
    "                query_state=describe_statement['Status']\n",
    "                while query_state in ['SUBMITTED','PICKED','STARTED']:\n",
    "                    time.sleep(2)            \n",
    "                    describe_statement=REDSHIFT.describe_statement(\n",
    "                                     Id=response['Id'],\n",
    "                                )\n",
    "                    query_state=describe_statement['Status']\n",
    "                if query_state == \"FINISHED\":                \n",
    "                    break \n",
    "        \n",
    "        if max_execution == 0 and query_state == \"FAILED\":\n",
    "            print(f\"DEBUGGING FAILED IN {str(debug_count)} ATTEMPTS\")\n",
    "        elif alert:\n",
    "            pass\n",
    "        else:           \n",
    "            max_attempts = 5\n",
    "            attempts = 0\n",
    "            while attempts < max_attempts:\n",
    "                try:\n",
    "                    time.sleep(1)\n",
    "                    statement_result = REDSHIFT.get_statement_result(\n",
    "                        Id=response['Id']\n",
    "                    )\n",
    "                    break\n",
    "\n",
    "                except REDSHIFT.exceptions.ResourceNotFoundException as e:\n",
    "                    attempts += 1\n",
    "                    time.sleep(5)\n",
    "    if max_execution == 0 and query_state == \"FAILED\":\n",
    "        df=f\"DEBUGGING FAILED IN {str(debug_count)} ATTEMPTS. NO RESULT AVAILABLE\"\n",
    "    elif alert:\n",
    "        df=\"I AM NOT PERMITTED TO MODIFY THIS TABLE, CONTACT ADMIN.\"     \n",
    "    else:\n",
    "        df=get_redshift_table_result(statement_result)\n",
    "    return df, q_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "3cab616f-b529-4646-961f-0bb1e420e018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def redshift_qna(params):\n",
    "    \"\"\"\n",
    "    Execute a Q&A process for generating SQL queries based on user questions.\n",
    "    Args:\n",
    "        params (dict): A dictionary containing parameters including table name, database name, prompt, etc.\n",
    "    Returns:\n",
    "        tuple: A tuple containing the response, generated SQL statement, and query output.\n",
    "    \"\"\"\n",
    "    sql1=f\"SELECT table_catalog,table_schema,table_name,column_name,ordinal_position,is_nullable,data_type FROM information_schema.columns WHERE table_schema='{params['db-schema']}'\"\n",
    "    sql2=[]\n",
    "    for table in params['tables']:\n",
    "        sql2.append(f\"SELECT * from {params['database']}.{params['db-schema']}.{table} LIMIT 3\")\n",
    "    sqls=[sql1]+sql2\n",
    "    \n",
    "    question=params['prompt']\n",
    "    results=execute_query_with_pagination(sqls, IDENTIFIER, params['database'],params['serverless'], DB_USER)    \n",
    "    # print(results)\n",
    "    col_names=results[0].split('\\n')[0]\n",
    "    \n",
    "    observations=\"\\n\".join(sorted(results[0].split('\\n')[1:])).strip()\n",
    "\n",
    "    params['schema']=f\"{col_names}\\n{observations}\"\n",
    "    \n",
    "    params['sample']=''\n",
    "    for ids,examples in enumerate(results[1:]):\n",
    "        params['sample']+=f\"<{params['tables'][ids]}_table>\\n{examples}</{params['tables'][ids]}_table>\\n\"\n",
    "\n",
    "    model=\"claude\"\n",
    "    with open(f\"prompt/{params['prompt-type']}/{model}-sql.txt\",\"r\") as f:\n",
    "        prompts=f.read()\n",
    "    values = {\n",
    "    \"schema\": params['schema'],\n",
    "    \"sample\": params['sample'],\n",
    "    \"question\": question,\n",
    "    }\n",
    "    prompts=prompts.format(**values)\n",
    "    # print(prompts)\n",
    "    q_s=query_llm(prompts,params)\n",
    "    sql_pattern = re.compile(r'<sql>(.*?)(?:</sql>|$)', re.DOTALL)           \n",
    "    sql_match = re.search(sql_pattern, q_s)\n",
    "    q_s = sql_match.group(1) \n",
    "    ### Guardrails to prevent the LLM from altering tables\n",
    "    if any(keyword in q_s for keyword in [\"CREATE\", \"DROP\", \"ALTER\",\"INSERT\",\"UPDATE\",\"TRUNCATE\",\"DELETE\",\"MERGE\",\"REPLACE\",\"UPSERT\"]):\n",
    "        output=\"I AM NOT PERMITTED TO MODIFY THIS TABLE, CONTACT ADMIN.\"\n",
    "        response=\"I AM NOT PERMITTED TO MODIFY THIS TABLE, CONTACT ADMIN.\"\n",
    "    else:\n",
    "        output, q_s=single_execute_query(params,q_s, IDENTIFIER, params['database'], question, params['serverless'],DB_USER) \n",
    "        # Handle results that exceed LLM token window length\n",
    "        input_token=CLAUDE.count_tokens(output) if \"claude\" in params['text-model'].lower() else mistral_counter(\"mistralai/Mixtral-8x7B-v0.1\").encode(output)\n",
    "        if input_token>180000:    \n",
    "            csv_rows=output.split('\\n')\n",
    "            chunk_rows=chunk_csv_rows(csv_rows, 50000)\n",
    "            initial_summary=[]\n",
    "            for chunk in chunk_rows:\n",
    "                model=\"claude\" \n",
    "                with open(f\"prompt/{params['prompt-type']}/{model}-text-gen.txt\",\"r\") as f:\n",
    "                    prompts=f.read()\n",
    "                values = {   \n",
    "                \"sql\":q_s,\n",
    "                \"csv\": output,       \n",
    "                \"question\":question,\n",
    "                }\n",
    "                prompts=prompts.format(**values)\n",
    "                initial_summary.append(qna_llm(prompts,params))\n",
    "            prompts = f'''You are a helpful and truthful assistant.\n",
    "Here are multiple answer for a question on different subset of a tabular data:\n",
    "#######\n",
    "{initial_summary}\n",
    "#######\n",
    "Question: {question}\n",
    "Based on the given question above, merege all answers provided in a coherent singular answer'''\n",
    "            response=qna_llm(prompts,params)\n",
    "\n",
    "        else:        \n",
    "            model=\"claude\" \n",
    "            with open(f\"prompt/{params['prompt-type']}/{model}-text-gen.txt\",\"r\") as f:\n",
    "                prompts=f.read()\n",
    "            values = {   \n",
    "            \"sql\":q_s,\n",
    "            \"csv\": output,       \n",
    "            \"question\":question,\n",
    "            }\n",
    "            prompts=prompts.format(**values)                \n",
    "            response=qna_llm(prompts, params) \n",
    "    return response, q_s,output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0427b27-bb38-4cce-9054-ab51507a37f1",
   "metadata": {},
   "source": [
    "#### Change parameters below to those of your Redshift resource\n",
    "For Redshift provisioned capacity set `IDENTIFIER` to your cluster-identifier for your redshift cluster and `DB_USER` to admin username and set `serverless` to False \\\n",
    "For redshidft serverless, set `IDENTIFIER` to your work-group name and set `serverless` to True\n",
    "\n",
    "Change the **database_index** and **schema_index** to the specific database and schema where the tables are located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "f69fcae3-32f0-4048-a2cf-74183b928182",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here is the list of Databse in your account ['awsdatacatalog', 'dev']\n",
      "here is the list of Schema ['catalog_history', 'information_schema', 'pg_auto_copy', 'pg_automv', 'pg_catalog', 'pg_internal', 'pg_s3', 'public'] in dev databse\n",
      "here is the list of tables ['holdings_pkey', 'cars', 'category', 'date', 'event', 'holdings', 'listing', 'sales', 'users', 'venue'] in dev databse and public schema\n"
     ]
    }
   ],
   "source": [
    "IDENTIFIER = 'redshift-cluster-llm'\n",
    "DATABASE = 'dev'\n",
    "serverless=False # Toggle this to True if using Redshift Serverless\n",
    "DB_USER = 'faynxe' if not serverless else None\n",
    "\n",
    "\n",
    "db=get_db_redshift(IDENTIFIER, DATABASE,serverless,DB_USER) \n",
    "print(f\"here is the list of Databse in your account {db}\")\n",
    "# Select the database you want to query\n",
    "database_index=1\n",
    "\n",
    "schm=get_schema_redshift(IDENTIFIER, db[database_index],serverless,DB_USER)\n",
    "print(f\"here is the list of Schema {schm} in {db[database_index]} databse\")\n",
    "# Select Schema index databse\n",
    "schema_index=-1\n",
    "\n",
    "tables=get_tables_redshift(IDENTIFIER, db[database_index],schm[schema_index],serverless,DB_USER)\n",
    "print(f\"here is the list of tables {tables} in {db[database_index]} databse and {schm[schema_index]} schema\")\n",
    "\n",
    "tables=[x for x in tables if \"pkey\" not in x] #Remove any non-table name from list of returned tables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4c4a5e-086b-453a-aa33-bd9188409317",
   "metadata": {},
   "source": [
    "You can decide the number of tables to be loaded into the LLM prompt for query. For each table selected, the schema definition and sample rows are loaded into the LLM prompt.\n",
    "For single table query, you can pass the single table name in the params definition below for a given Database Schema.\n",
    "For query that requires insight into multiple tables, pass the list of tables in the params definition below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "536466a5-80a8-4a69-bc8e-b390cccc2432",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pass your question\n",
    "question=\"What are the list of bond holdings?\"\n",
    "\n",
    "params={'sql-token':700,'token':500,'tables':tables, # Tables must be in list format\n",
    "        'db-schema':schm, # Redshift Database SchemaName,\n",
    "        \"database\":db,\n",
    "        'temp':0.5,\n",
    "        \"serverless\": serverless, \n",
    "        'text-model':'anthropic.claude-3-sonnet-20240229-v1:0', # SQL to NL model\n",
    "        \"prompt-type\":\"redshift\",\n",
    "        \"sql_model\":\"anthropic.claude-3-sonnet-20240229-v1:0\",#\"anthropic.claude-3-sonnet-20240229-v1:0\"\"anthropic.claude-v2\",\"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "        \"prompt\":question,\n",
    "       \"chat_history\":[],\n",
    "       \"system_message\":\"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642ae516-41e5-453e-be1a-ca7de1c1e9ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Quesry the redshift table\n",
    "ress=redshift_qna(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "73f7a388-c7dd-40df-bda1-3719044129d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "Based on the SQL result, the list of bond holdings includes:\n",
      "\n",
      "1. U.S. Treasury Bond\n",
      "2. Apple Inc. Corporate Bond\n",
      "3. U.S. Treasury Note\n",
      "4. Apple Inc. Corporate Bond\n",
      "5. Amazon.com, Inc. Corporate Bond\n",
      "6. Microsoft Corporation Corporate Bond\n",
      "7. Amazon.com, Inc. Corporate Bond\n",
      "\n",
      "The result shows the security_name, ticker_symbol, quantity, market_value, coupon_rate, maturity_date, and credit_rating for each bond holding. The security_type filter in the SQL query ensures that only bonds are included in the result.\n",
      "\n",
      "SQL:\n",
      "\n",
      "SELECT security_name, ticker_symbol, quantity, market_value, coupon_rate, maturity_date, credit_rating\n",
      "FROM dev.public.holdings\n",
      "WHERE security_type = 'Bond';\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Result and SQL Statement\n",
    "print(f\"Answer:\\n{ress[0]}\\n\\nSQL:\\n{ress[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "884c31f9-917e-45a3-94fb-1c05eef677b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>security_name</th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>quantity</th>\n",
       "      <th>market_value</th>\n",
       "      <th>coupon_rate</th>\n",
       "      <th>maturity_date</th>\n",
       "      <th>credit_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U.S. Treasury Bond</td>\n",
       "      <td>True</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2028-05-15</td>\n",
       "      <td>AAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apple Inc. Corporate Bond</td>\n",
       "      <td>True</td>\n",
       "      <td>500.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2026-09-01</td>\n",
       "      <td>AA+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U.S. Treasury Note</td>\n",
       "      <td>True</td>\n",
       "      <td>750.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>1.63</td>\n",
       "      <td>2025-02-15</td>\n",
       "      <td>AAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apple Inc. Corporate Bond</td>\n",
       "      <td>True</td>\n",
       "      <td>400.0</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2027-01-15</td>\n",
       "      <td>AA+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazon.com, Inc. Corporate Bond</td>\n",
       "      <td>True</td>\n",
       "      <td>300.0</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>3.38</td>\n",
       "      <td>2031-05-01</td>\n",
       "      <td>AA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Microsoft Corporation Corporate Bond</td>\n",
       "      <td>True</td>\n",
       "      <td>800.0</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2031-07-01</td>\n",
       "      <td>AAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Amazon.com, Inc. Corporate Bond</td>\n",
       "      <td>True</td>\n",
       "      <td>200.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>3.15</td>\n",
       "      <td>2032-03-01</td>\n",
       "      <td>AA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          security_name  ticker_symbol  quantity  \\\n",
       "0                    U.S. Treasury Bond           True    1000.0   \n",
       "1             Apple Inc. Corporate Bond           True     500.0   \n",
       "2                    U.S. Treasury Note           True     750.0   \n",
       "3             Apple Inc. Corporate Bond           True     400.0   \n",
       "4       Amazon.com, Inc. Corporate Bond           True     300.0   \n",
       "5  Microsoft Corporation Corporate Bond           True     800.0   \n",
       "6       Amazon.com, Inc. Corporate Bond           True     200.0   \n",
       "\n",
       "   market_value  coupon_rate maturity_date credit_rating  \n",
       "0       95000.0         2.75    2028-05-15           AAA  \n",
       "1       50000.0         3.25    2026-09-01           AA+  \n",
       "2       72000.0         1.63    2025-02-15           AAA  \n",
       "3       40000.0         2.85    2027-01-15           AA+  \n",
       "4       30000.0         3.38    2031-05-01            AA  \n",
       "5       80000.0         3.00    2031-07-01           AAA  \n",
       "6       20000.0         3.15    2032-03-01            AA  "
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SQL Query Result\n",
    "df=pd.read_csv(StringIO(ress[2]))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "5d69173b-db5c-4b96-be24-7407a48342eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A solar eclipse occurs when the moon passes between the sun and the Earth, temporarily blocking the sun's rays and casting a shadow on parts of Earth. There are a few key things to know about solar eclipses:\n",
      "\n",
      "- Total Solar Eclipse: This is when the moon's apparent size in the sky completely covers the sun, revealing the sun's outer atmosphere called the corona. The moon casts its umbra (darkest part of the shadow) on Earth's surface along a narrow path.\n"
     ]
    }
   ],
   "source": [
    "prompt={\n",
    "  \"prompt\": \"hello\",\n",
    "  \"max_tokens_to_sample\": 70,\n",
    "  \"temperature\": 0.1,\n",
    "  # \"top_k\": 250,\n",
    "  # \"top_p\":params['top_p'],  \n",
    "     # \"stop_sequences\": []\n",
    "}\n",
    "\n",
    "# content=[{\n",
    "#         \"type\": \"text\",\n",
    "#         \"text\": prompt\n",
    "#             }]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "50d32528-6666-4346-9429-f0b617734689",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for stream in output['body']:\n",
    "    print(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "c41d13e8-4342-4fad-ae4d-8754534e52ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'msg_01D7r6AwfZgxCLP3yj7bNCAK',\n",
       " 'type': 'message',\n",
       " 'role': 'assistant',\n",
       " 'content': [{'type': 'text', 'text': 'Hello! How can I assist you today?'}],\n",
       " 'model': 'claude-3-sonnet-28k-20240229',\n",
       " 'stop_reason': 'end_turn',\n",
       " 'stop_sequence': None,\n",
       " 'usage': {'input_tokens': 8, 'output_tokens': 12}}"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca54356-9316-47b7-997f-65760d928a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = \"\"\n",
    "    i = 1\n",
    "    if stream:\n",
    "        for event in stream:\n",
    "            chunk = event.get('chunk')\n",
    "            if  chunk:\n",
    "                chunk_obj = json.loads(chunk.get('bytes').decode())\n",
    "                if \"delta\" in chunk_obj:                    \n",
    "                    delta = chunk_obj['delta']\n",
    "                    if \"text\" in delta:\n",
    "                        text=delta['text'] \n",
    "                        print(text, end=\"\")\n",
    "                        answer+=str(text)       \n",
    "                        i+=1"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
